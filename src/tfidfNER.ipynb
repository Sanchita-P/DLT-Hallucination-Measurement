{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"lamini/lamini_docs\"\n",
    "datasets = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for qa_pair in datasets['train']:\n",
    "    _sentence = (qa_pair['question'] + ' ' + qa_pair['answer']).replace(\"\\\\n\", \" \")\n",
    "    data.append(_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top tf-idf words from the QA docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             term        rank\n",
      "1848       lamini  103.728120\n",
      "3253         text   54.182434\n",
      "834          data   47.727913\n",
      "2100        model   41.152211\n",
      "142            ai   39.693581\n",
      "...           ...         ...\n",
      "3523     welcomes    0.066917\n",
      "273     attending    0.066917\n",
      "816     curiosity    0.066917\n",
      "2385        plays    0.066917\n",
      "888   departments    0.066917\n",
      "\n",
      "[3574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def top_tfidf_words(sentences, top_n=100):\n",
    "    # Initialize a TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # Fit and transform the sentences\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Get feature names (words)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Sum TF-IDF for each term across all documents\n",
    "    sums = tfidf_matrix.sum(axis=0)\n",
    "\n",
    "    # Create a dataframe with words and their corresponding sums\n",
    "    data = []\n",
    "    for col, term in enumerate(feature_names):\n",
    "        data.append((term, sums[0, col]))\n",
    "\n",
    "    ranking = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "    ranking = ranking.sort_values('rank', ascending=False)\n",
    "\n",
    "    return ranking\n",
    "\n",
    "# Get top 100 TF-IDF words\n",
    "top_words = top_tfidf_words(data)\n",
    "print(top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>lamini</td>\n",
       "      <td>103.728120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>text</td>\n",
       "      <td>54.182434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>data</td>\n",
       "      <td>47.727913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>model</td>\n",
       "      <td>41.152211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ai</td>\n",
       "      <td>39.693581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>specific</td>\n",
       "      <td>39.275116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>llm</td>\n",
       "      <td>38.782491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>generate</td>\n",
       "      <td>38.024717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>language</td>\n",
       "      <td>36.952806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>models</td>\n",
       "      <td>35.657740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>documentation</td>\n",
       "      <td>35.199831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>used</td>\n",
       "      <td>30.566909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>training</td>\n",
       "      <td>30.283421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>yes</td>\n",
       "      <td>30.276885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>using</td>\n",
       "      <td>30.247232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>engine</td>\n",
       "      <td>29.922702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>code</td>\n",
       "      <td>29.597643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>does</td>\n",
       "      <td>29.049493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>use</td>\n",
       "      <td>28.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>generating</td>\n",
       "      <td>27.560178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>python</td>\n",
       "      <td>21.800063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>library</td>\n",
       "      <td>21.608876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>fine</td>\n",
       "      <td>21.374396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>tasks</td>\n",
       "      <td>20.387001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>generated</td>\n",
       "      <td>19.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>performance</td>\n",
       "      <td>19.356886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>handle</td>\n",
       "      <td>18.488730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>information</td>\n",
       "      <td>17.791884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>provides</td>\n",
       "      <td>17.707144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>support</td>\n",
       "      <td>17.375321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>generation</td>\n",
       "      <td>17.356582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>learning</td>\n",
       "      <td>17.289468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>llms</td>\n",
       "      <td>16.911848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>function</td>\n",
       "      <td>16.870324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>examples</td>\n",
       "      <td>16.817743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>additionally</td>\n",
       "      <td>16.766441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>help</td>\n",
       "      <td>16.724243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>trained</td>\n",
       "      <td>16.605737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>output</td>\n",
       "      <td>16.053093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>features</td>\n",
       "      <td>16.032457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term        rank\n",
       "1848         lamini  103.728120\n",
       "3253           text   54.182434\n",
       "834            data   47.727913\n",
       "2100          model   41.152211\n",
       "142              ai   39.693581\n",
       "3014       specific   39.275116\n",
       "1937            llm   38.782491\n",
       "1433       generate   38.024717\n",
       "1855       language   36.952806\n",
       "2103         models   35.657740\n",
       "996   documentation   35.199831\n",
       "3418           used   30.566909\n",
       "3311       training   30.283421\n",
       "3569            yes   30.276885\n",
       "3423          using   30.247232\n",
       "1119         engine   29.922702\n",
       "553            code   29.597643\n",
       "999            does   29.049493\n",
       "3417            use   28.918751\n",
       "1436     generating   27.560178\n",
       "2549         python   21.800063\n",
       "1895        library   21.608876\n",
       "1324           fine   21.374396\n",
       "3210          tasks   20.387001\n",
       "1434      generated   19.429000\n",
       "2340    performance   19.356886\n",
       "1522         handle   18.488730\n",
       "1689    information   17.791884\n",
       "2522       provides   17.707144\n",
       "3160        support   17.375321\n",
       "1437     generation   17.356582\n",
       "1876       learning   17.289468\n",
       "1938           llms   16.911848\n",
       "1403       function   16.870324\n",
       "1190       examples   16.817743\n",
       "100    additionally   16.766441\n",
       "1551           help   16.724243\n",
       "3310        trained   16.605737\n",
       "2274         output   16.053093\n",
       "1296       features   16.032457"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words.iloc[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2991976/789917945.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if x[1][0] not in glove_words:\n",
      "/tmp/ipykernel_2991976/789917945.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if x[1][0] in ww:\n",
      "/tmp/ipykernel_2991976/789917945.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(count, x[1][0], x[1][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 lamini 103.72812011895267\n",
      "2 llms 16.911848466611534\n",
      "6 chatbots 4.882678581053292\n",
      "8 llamaindex 3.4261720020630055\n",
      "10 hyperparameters 3.108621252031838\n",
      "18 hyperparameter 2.011977616234558\n",
      "78 tpus 0.33744743288350704\n"
     ]
    }
   ],
   "source": [
    "ww = ['chatbots',\n",
    " 'hyperparameter',\n",
    " 'hyperparameters',\n",
    " 'lamini',\n",
    " 'llamaindex',\n",
    " 'llms',\n",
    " 'tpus']\n",
    "count = 0\n",
    "for i, x in enumerate(top_words.iterrows()):\n",
    "   if x[1][0] not in glove_words:\n",
    "      count += 1\n",
    "   if x[1][0] in ww:\n",
    "     print(count, x[1][0], x[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter domains specific words (Remove GloVe words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = []\n",
    "with open(\"/nethome/ss651/DLT-Hallucination-Measurement/glove.6B.100d.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        word = line.split()[0]\n",
    "        glove_words.append(word)\n",
    "\n",
    "important_words = top_words[\"term\"].tolist()\n",
    "\n",
    "filtered_words = []\n",
    "\n",
    "for word in important_words:\n",
    "    if word not in glove_words:\n",
    "        filtered_words.append(word)\n",
    "\n",
    "filtered_words =  sorted(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10mbps',\n",
       " '20gb',\n",
       " '23465125488609597',\n",
       " '3627493468056o869069738746723563537579456800',\n",
       " '37k',\n",
       " '410m',\n",
       " '70k',\n",
       " '800k',\n",
       " '84092384972847832590458',\n",
       " '__call__',\n",
       " '__call___',\n",
       " '__callable__',\n",
       " '__init__',\n",
       " 'add_data',\n",
       " 'add_improve_statement',\n",
       " 'add_improve_statements',\n",
       " 'add_metric',\n",
       " 'add_model',\n",
       " 'animal_stories',\n",
       " 'backoff',\n",
       " 'bad_examples',\n",
       " 'basemodel',\n",
       " 'basemodels',\n",
       " 'byeeee',\n",
       " 'camelinae',\n",
       " 'cancel_job',\n",
       " 'changelog',\n",
       " 'chatbot',\n",
       " 'chatbots',\n",
       " 'chatgpt',\n",
       " 'check_job_status',\n",
       " 'circular_operation',\n",
       " 'cohere_throughput',\n",
       " 'compare_equal_metric',\n",
       " 'composable',\n",
       " 'configure_llama',\n",
       " 'databricks',\n",
       " 'dataframe',\n",
       " 'datasetbalancer',\n",
       " 'debiasing',\n",
       " 'deduped',\n",
       " 'detaileddescriptors',\n",
       " 'dhqdnoerijtoigjro',\n",
       " 'diamos',\n",
       " 'distributeddataparallel',\n",
       " 'eachadea',\n",
       " 'edit_config',\n",
       " 'eleutherai',\n",
       " 'erqiujlkcmabhsvandlkfhpghl',\n",
       " 'error_handling',\n",
       " 'explainability',\n",
       " 'feedbackoperation',\n",
       " 'filter_fn',\n",
       " 'fostes',\n",
       " 'fucntion',\n",
       " 'full_balance_dataset',\n",
       " 'gen_queue_batch',\n",
       " 'gen_submit_training_job',\n",
       " 'get_job_result',\n",
       " 'get_job_results',\n",
       " 'get_response',\n",
       " 'getargumentoperation',\n",
       " 'good_examples',\n",
       " 'gpt3',\n",
       " 'gpt4',\n",
       " 'grafana',\n",
       " 'gridsearchcv',\n",
       " 'hdsdvtqwdeyhjgfgkhpjknl',\n",
       " 'hgbmnjbdgvdsbhdfj',\n",
       " 'hiiiiiiiiiiiiiiii',\n",
       " 'home_yaml_config',\n",
       " 'horovod',\n",
       " 'huggingface',\n",
       " 'hyperparameter',\n",
       " 'hyperparameters',\n",
       " 'instantiating',\n",
       " 'interpretability',\n",
       " 'is_peft_model',\n",
       " 'istio',\n",
       " 'iterrows',\n",
       " 'jgdaygwahifjolmadkjwbh',\n",
       " 'jkndjwayxbuijkadn',\n",
       " 'jupyter',\n",
       " 'kubeflow',\n",
       " 'kubernetes',\n",
       " 'lamini',\n",
       " 'lamini_objects',\n",
       " 'laminiai',\n",
       " 'langchain',\n",
       " 'length_penalty',\n",
       " 'librarybase',\n",
       " 'linkerd',\n",
       " 'llama_animal',\n",
       " 'llamaapierror',\n",
       " 'llamaindex',\n",
       " 'llamasoft',\n",
       " 'llms',\n",
       " 'lmkjahsuyqfshgx',\n",
       " 'make_discriminator',\n",
       " 'make_questions',\n",
       " 'max_retries',\n",
       " 'max_tokens',\n",
       " 'microservices',\n",
       " 'misconfigured',\n",
       " 'mlcommons',\n",
       " 'mlflow',\n",
       " 'mlops',\n",
       " 'mlperf',\n",
       " 'model_name',\n",
       " 'mosaicml',\n",
       " 'my_data',\n",
       " 'n_legs',\n",
       " 'neox',\n",
       " 'ofcourse',\n",
       " 'onestream',\n",
       " 'onnx',\n",
       " 'openaccess',\n",
       " 'openai',\n",
       " 'overfit',\n",
       " 'pandoc',\n",
       " 'parallelize',\n",
       " 'parse_response',\n",
       " 'peft',\n",
       " 'performant',\n",
       " 'persontype',\n",
       " 'powerml',\n",
       " 'preprocess',\n",
       " 'preprocessed',\n",
       " 'pydantic',\n",
       " 'pypi',\n",
       " 'pytorch',\n",
       " 'qrdsrqfduwnfkkhopktylhmdknjhqwgsagvsxhajbfnkdmg',\n",
       " 'ratelimiter',\n",
       " 'ratelimiterror',\n",
       " 'repetition_penalty',\n",
       " 'retries',\n",
       " 'retweets',\n",
       " 'rlhf',\n",
       " 'rnns',\n",
       " 'run_all',\n",
       " 'runtimeerror',\n",
       " 'savedmodel',\n",
       " 'sparksql',\n",
       " 'stochastic_balance_dataset',\n",
       " 'submit_job',\n",
       " 'subword',\n",
       " 'subwords',\n",
       " 'tensorflow',\n",
       " 'test_cache',\n",
       " 'test_multiple_models',\n",
       " 'test_output_str',\n",
       " 'test_parallel_complex',\n",
       " 'test_parallel_simple',\n",
       " 'test_random',\n",
       " 'testfilter',\n",
       " 'testoutputstr',\n",
       " 'tokenizer',\n",
       " 'tpus',\n",
       " 'underfitting',\n",
       " 'undersampling',\n",
       " 'unittest',\n",
       " 'value_to_dict',\n",
       " 'vpcs',\n",
       " 'waitlist',\n",
       " 'weasyprint',\n",
       " 'websockets',\n",
       " 'wizardlm',\n",
       " 'write_story']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the domain specific words with NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../results/train_ners.csv\")\n",
    "ner_list = list(df[\"NERS\"].dropna())\n",
    "\n",
    "ners = []\n",
    "for ner in ner_list:\n",
    "    ners.extend(ner.lower().replace(\"`\",\"\").split(\", \"))\n",
    "\n",
    "filtered_ners = []\n",
    "for ner in ners:\n",
    "    if ner not in glove_words:\n",
    "        filtered_ners.append(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('../results/important_words.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for _word in filtered_words:\n",
    "        writer.writerow([_word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Lamini Specific function calls from the domain specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "document_content = ' '.join(data)\n",
    "\n",
    "# Regex pattern for function calls\n",
    "pattern = r'\\b[a-zA-Z0-9]+\\w*_+\\w+?(?<!\\.py)\\b|\\b[a-zA-Z0-9]+\\w+\\(\\)(?<!\\.py\\b)'\n",
    "\n",
    "entities = re.findall(pattern, document_content)\n",
    "entities = sorted(list(set(entities)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it possible to customize the level of specificity in the generated output? Yes, it is possible to customize the level of specificity in the generated output. This can be achieved by adjusting the input parameters and output type in the LLM Engine function, as demonstrated in the \"TestOutputStr\" class in the \"test_output_str.py\" file. By defining specific input parameters and output types, the generated output can be tailored to meet the desired level of specificity.\n"
     ]
    }
   ],
   "source": [
    "for x in data:\n",
    "    if  'test_output_str' in x:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entities = [\n",
    " 'add_data',\n",
    " 'add_improve_statements',\n",
    " 'add_metric',\n",
    " 'add_model',\n",
    " 'bad_examples',\n",
    " 'cancel_job',\n",
    " 'check_job_status',\n",
    " 'circular_operation',\n",
    " 'compare_equal_metric',\n",
    " 'configure_llama',\n",
    " 'edit_config',\n",
    " 'error_handling',\n",
    " 'filter_fn',\n",
    " 'full_balance_dataset',\n",
    " 'gen_queue_batch',\n",
    " 'gen_submit_training_job',\n",
    " 'get_job_results',\n",
    " 'get_response',\n",
    " 'good_examples',\n",
    " 'improve()',\n",
    " 'is_peft_model',\n",
    " 'length_penalty',\n",
    " 'llm()',\n",
    " 'make_discriminator',\n",
    " 'make_questions',\n",
    " 'max_retries',\n",
    " 'max_tokens',\n",
    " 'model_name',\n",
    " 'parse_response',\n",
    " 'repetition_penalty',\n",
    " 'run_all',\n",
    " 'sample()',\n",
    " 'stochastic_balance_dataset',\n",
    " 'submit_job',\n",
    " 'test_cache',\n",
    " 'test_output_str',\n",
    " 'test_parallel_complex',\n",
    " 'test_parallel_simple',\n",
    " 'value_to_dict',\n",
    " 'write_story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file_path = \"../results/filtered_entities.csv\"\n",
    "\n",
    "with open(file_path, 'w', newline='') as file:\n",
    "   writer = csv.writer(file)\n",
    "   for _word in filtered_entities:\n",
    "      writer.writerow([_word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Context for the filtered words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "\n",
    "for func in filtered_entities:\n",
    "    _context = []\n",
    "    for qa in data:\n",
    "        if func in qa:\n",
    "            _context.append(qa)\n",
    "    context.append([func, ' '.join(_context)])\n",
    "\n",
    "import pickle as pkl\n",
    "pkl.dump(context, open(\"context.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file_path = 'context.csv'\n",
    "\n",
    "# Writing to a CSV file\n",
    "with open(file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Entity\", \"Context\"])\n",
    "    writer.writerows(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pkl.load(open(\"summary.pkl\", \"rb\"))\n",
    "\n",
    "file_path = 'summary.csv'\n",
    "\n",
    "# Writing to a CSV file\n",
    "with open(file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Entity\", \"Summary\"])\n",
    "    writer.writerows(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
