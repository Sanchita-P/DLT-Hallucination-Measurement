Entity,Summary
add_data,"  The `add_data()` function in Lamini allows you to add training data to the LLM Engine, enabling the model to learn and improve its performance."
add_improve_statements,"  In Lamini, the `add_improve_statements()` function allows adding multiple improve statements to the LLM engine."
add_metric,"  The `add_metric` method in Lamini allows you to add a metric to compare the generated output to a target output, and train the LLM Engine using the `fit` method."
add_model,"  The ""add_model"" method in Lamini's python library allows for creating multiple models with different parameters and output types, which can be used to fine-tune the model on a specific dataset for dialogue generation tasks."
bad_examples,  The `bad_examples` list provides the model with incorrect or undesired output examples to learn from and improve its performance.
cancel_job,"  The `cancel_job()` function in Lamini stops a running job by sending a request to the server, releasing any resources used, and returning a response indicating the cancellation's success or failure."
check_job_status,"  The `check_job_status()` function in Lamini provides real-time updates on the status of a job, including running, completed, or failed, and may provide additional details such as start and end times and error messages."
circular_operation,"  ""Circular_operation"" is a function that performs a complex operation involving multiple layers of a neural network in a circular manner."
compare_equal_metric,"  The ""compare_equal_metric.py"" file provides code samples for defining and adding custom metrics to a program for execution by the Llama large language model engine."
configure_llama,  The `~/.powerml/configure_llama.yaml` file stores the Lamini API key for automatic loading by the Lamini Python package.
edit_config,"  The ""edit_config"" function in Lamini allows users to update configuration settings, including model updates or retraining, without disrupting their software application."
error_handling,"  The ""error_handling"" function in Lamini's LLM Engine provides guidelines and resources for handling errors and exceptions in the code, including logging and reporting mechanisms."
filter_fn,  The `filter_fn` parameter allows for custom filtering of generated output based on a provided function.
full_balance_dataset,"  The ""full_balance_dataset"" method in Lamini's DatasetBalancer class balances a dataset without random sampling, using embeddings to compare data points and remove duplicates based on a threshold."
gen_queue_batch,"  The `gen_queue_batch()` function in Lamini allows you to queue a batch of values for processing, enabling you to track the status of the job through the `check_job_status()` function."
gen_submit_training_job,  The `gen_submit_training_job()` function in Lamini submits a training job to the platform for processing.
get_job_results,  The `get_job_results` method in Lamini retrieves the results of a previously submitted job.
get_response,"  ""get_response"" retrieves a response from the Llama API and handles errors by retrying up to 5 times before raising a runtime error."
good_examples,"  The `good_examples` argument in Lamini's `improve()` function provides the model with a list of high-quality examples of the desired output, which the model can learn from to improve its performance."
improve(),"  The `improve()` function in Lamini fine-tunes a model's output by providing good and bad examples of the desired output, allowing the model to learn from its mistakes and improve its performance."
is_peft_model,"  The ""is_peft_model"" parameter in Lamini allows for better interpretability of customized LLMs by enabling the Partially Extractive Fine-Tuning (PEFT) method, which improves the model's ability to explain its predictions."
length_penalty,"  In Lamini, ""length_penalty"" refers to a parameter that penalizes generated text that exceeds a specified length, encouraging the model to produce concise output."
llm(),"  The `llm()` function in Lamini allows for the creation of customized language models with interpretability and explainability features, such as the PEFT method and parse_response function."
make_discriminator,"  ""Make_discriminator"" function in Lamini provides options for different model types and hyperparameter tuning using GridSearchCV to evaluate the performance of a customized discriminator model."
make_questions,"  ""Make questions"" generates customized questions based on both text and other types of data for multimodal learning in Lamini."
max_retries,  The `max_retries` parameter allows for limiting the number of retries in case the generated output does not satisfy a specified condition.
max_tokens,"  The ""max_tokens"" parameter in Lamini controls the maximum length of generated text outputs, allowing for precise control over text length."
model_name,"  The ""model_name"" parameter in Lamini allows users to specify the name of a pre-trained language model to use for text generation, customization, or inference."
parse_response,  The `parse_response` function strips leading and trailing whitespace from the response string and extracts the most relevant information from the model's output.
repetition_penalty,"  The ""repetition_penalty"" parameter in Lamini allows for controlling the repetition of generated text by imposing a penalty on repeated words or phrases."
run_all,"  ""Runs all models in parallel using the @llm.parallel decorator and the llama.run_all method."""
sample(),"  The `sample()` function in Lamini generates text outputs based on a given prompt or context, using a pre-trained language model to predict the most likely next word or sequence of words."
stochastic_balance_dataset,"  The `stochastic_balance_dataset` method in `balancer.py` randomly samples from a balanced index to add new data points to a small dataset with limited annotations, improving the performance of the model."
submit_job,"  The `submit_job()` function in Lamini submits a machine learning training job to the cluster for processing, handling background processing and job scheduling."
test_cache,"  In the provided code, the ""test_cache"" function compares the execution time of the code with and without caching to test the effectiveness of the caching mechanism."
test_output_str,"  In the ""test_output_str"" function, the level of specificity in the generated output can be customized by adjusting input parameters and output types in the LLM Engine function."
test_parallel_complex,"  In the ""test_parallel_complex"" method, the `circular_operation` function is parallelized using the `llm.parallel` decorator, and all models are run in parallel using the `llama.run_all` method."
test_parallel_simple,"  In the ""test_parallel_simple"" method, multiple models are run in parallel using the `llama.run_all` method to test the code's ability to handle concurrency and parallelism."
value_to_dict,  The `value_to_dict()` function in Lamini converts examples to a dictionary format for training data.
write_story,"  The ""write_story"" function in Lamini's python library generates a story based on user input, allowing for fine-grained control over creativity and randomness."
